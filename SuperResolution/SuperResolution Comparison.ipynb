{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d34926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D,AveragePooling2D,Conv2DTranspose, Input, Concatenate, Add, BatchNormalization, Activation, MultiHeadAttention\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#путь к тестовому изображению\n",
    "image_path = \"C:/users/user/desktop/8k_128/1313693129_71d0b21c63.jpg\"\n",
    "original_image = cv2.imread(image_path)\n",
    "\n",
    "original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "original_image = tf.image.resize(tf.cast(original_image, tf.float32)/256, (128, 128))\n",
    "small_image = tf.image.resize(original_image, (32, 32), method = \"bicubic\")\n",
    "bicubic_result = tf.image.resize(small_image, (128, 128), method = \"bicubic\")\n",
    "plt.imshow(bicubic_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f471947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esrgan от tensorflow\n",
    "SAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\"\n",
    "model_upscaler = hub.load(SAVED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69079da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert\n",
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
    "\n",
    "def process_text(text_batch):\n",
    "    text_preprocessed = bert_preprocess_model(text_batch)\n",
    "    bert_results = bert_model(text_preprocessed)\n",
    "    return bert_results[\"pooled_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "esrgan_result = model_upscaler(tf.expand_dims(small_image*256, axis = 0))[0]/256\n",
    "plt.imshow(esrgan_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_sr = tf.keras.models.load_model('regression_rs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af79380",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_result = regression_sr(tf.expand_dims(small_image, axis = 0))[0]\n",
    "plt.imshow(regression_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c12c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#подробнее о том, что тут происходит: https://keras.io/examples/generative/ddpm/\n",
    "class GaussianDiffusion:\n",
    "    \"\"\"Утилита для гауссовского диффузии.\n",
    "\n",
    "    Args:\n",
    "        beta_start: Начальное значение дисперсии\n",
    "        beta_end: Конечное значение дисперсии\n",
    "        timesteps: Количество временных шагов в процессе прямой, а затем обратной диффузии\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, beta_start=1e-4, beta_end=0.02, timesteps=1000, clip_min=-1.0, clip_max=1.0):\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.timesteps = timesteps\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max\n",
    "\n",
    "        # Определение линейного пространства дисперсии\n",
    "        self.betas = betas = np.linspace(\n",
    "            beta_start,\n",
    "            beta_end,\n",
    "            timesteps,\n",
    "            dtype=np.float64,  # Тут используется float64 для лучшей точности\n",
    "        )\n",
    "        self.num_timesteps = int(timesteps)\n",
    "\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
    "\n",
    "        self.betas = tf.constant(betas, dtype=tf.float32)\n",
    "        self.alphas_cumprod = tf.constant(alphas_cumprod, dtype=tf.float32)\n",
    "        self.alphas_cumprod_prev = tf.constant(alphas_cumprod_prev, dtype=tf.float32)\n",
    "\n",
    "        # Расчеты для диффузии q(x_t | x_{t-1}) и других\n",
    "        self.sqrt_alphas_cumprod = tf.constant(np.sqrt(alphas_cumprod), dtype=tf.float32)\n",
    "\n",
    "        self.sqrt_one_minus_alphas_cumprod = tf.constant(np.sqrt(1.0 - alphas_cumprod), dtype=tf.float32)\n",
    "\n",
    "        self.log_one_minus_alphas_cumprod = tf.constant(np.log(1.0 - alphas_cumprod), dtype=tf.float32)\n",
    "\n",
    "        self.sqrt_recip_alphas_cumprod = tf.constant(np.sqrt(1.0 / alphas_cumprod), dtype=tf.float32)\n",
    "        self.sqrt_recipm1_alphas_cumprod = tf.constant(np.sqrt(1.0 / alphas_cumprod - 1), dtype=tf.float32)\n",
    "\n",
    "        # Расчеты для апостериорной q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = (betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod))\n",
    "        self.posterior_variance = tf.constant(posterior_variance, dtype=tf.float32)\n",
    "\n",
    "        # Обрезка расчета логарифма, так как апостериорная дисперсия равна 0 в начале цепочки диффузии\n",
    "        self.posterior_log_variance_clipped = tf.constant(np.log(np.maximum(posterior_variance, 1e-20)), dtype=tf.float32)\n",
    "\n",
    "        self.posterior_mean_coef1 = tf.constant(betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod),dtype=tf.float32,)\n",
    "\n",
    "        self.posterior_mean_coef2 = tf.constant(\n",
    "            (1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod),dtype=tf.float32)\n",
    "\n",
    "    def _extract(self, a, t, x_shape):\n",
    "        \"\"\"Извлекает некоторые коэффициенты в указанных временных шагах,\n",
    "        затем изменяет форму на [batch_size, 1, 1, 1, 1, ...] совпадения форм.\n",
    "\n",
    "        Args:\n",
    "            a: Тензор для извлечения\n",
    "            t: Временной шаг, для которого коэффициенты должны быть извлечены\n",
    "            x_shape: Форма текущих выборок в батче\n",
    "        \"\"\"\n",
    "        batch_size = x_shape[0]\n",
    "        out = tf.gather(a, t)\n",
    "        return tf.reshape(out, [batch_size, 1, 1, 1])\n",
    "\n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        \"\"\"Извлекает среднее значение и дисперсию на текущем временном шаге.\n",
    "\n",
    "        Args:\n",
    "            x_start: Начальный образец (перед первым шагом диффузии)\n",
    "            t: Текущий временной шаг\n",
    "        \"\"\"\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        mean = self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start\n",
    "        variance = self._extract(1.0 - self.alphas_cumprod, t, x_start_shape)\n",
    "        log_variance = self._extract(self.log_one_minus_alphas_cumprod, t, x_start_shape)\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def q_sample(self, x_start, t, noise):\n",
    "        \"\"\"Диффузия данных.\n",
    "\n",
    "        Args:\n",
    "            x_start: Начальный образец (перед первым шагом диффузии)\n",
    "            t: Текущий временной шаг\n",
    "            noise: Добавляемый гауссовский шум на текущем временном шаге\n",
    "        Returns:\n",
    "            Диффузионные образцы на временном шаге `t`\n",
    "        \"\"\"\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        \n",
    "        return (\n",
    "            self._extract(self.sqrt_alphas_cumprod, t, tf.shape(x_start)) * x_start\n",
    "            + self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start_shape)\n",
    "            * noise\n",
    "        )\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        \n",
    "        return (\n",
    "            self._extract(self.sqrt_recip_alphas_cumprod, t, x_t_shape) * x_t\n",
    "            - self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t_shape) * noise\n",
    "        )\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        \"\"\"Вычисляет среднее значение и дисперсию диффузии апостериорной q(x_{t-1} | x_t, x_0).\n",
    "\n",
    "        Args:\n",
    "            x_start: Точка начала (образец) для вычисления апостериори\n",
    "            x_t: Образец на временном шаге `t`\n",
    "            t: Текущий временной шаг\n",
    "        Returns:\n",
    "            Апостериорное среднее значение и дисперсия на текущем временном шаге\n",
    "        \"\"\"\n",
    "\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        posterior_mean = (\n",
    "            self._extract(self.posterior_mean_coef1, t, x_t_shape) * x_start\n",
    "            + self._extract(self.posterior_mean_coef2, t, x_t_shape) * x_t\n",
    "        )\n",
    "        posterior_variance = self._extract(self.posterior_variance, t, x_t_shape)\n",
    "        posterior_log_variance_clipped = self._extract(self.posterior_log_variance_clipped, t, x_t_shape)\n",
    "        \n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, pred_noise, x, t, clip_denoised=True):\n",
    "        x_recon = self.predict_start_from_noise(x, t=t, noise=pred_noise)\n",
    "        if clip_denoised:\n",
    "            x_recon = tf.clip_by_value(x_recon, self.clip_min, self.clip_max)\n",
    "\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n",
    "        \n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "\n",
    "    def p_sample(self, pred_noise, x, t, clip_denoised=True):\n",
    "        \"\"\"Выборка из модели диффузии.\n",
    "\n",
    "        Args:\n",
    "            pred_noise: Шум, предсказанный моделью диффузии\n",
    "            x: Образцы на определенном временном шаге, для которого был предсказан шум\n",
    "            t: Текущий временной шаг\n",
    "            clip_denoised (bool): Нужно ли обрезать предсказанный шум в указанном диапазоне или нет.\n",
    "        \"\"\"\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(pred_noise, x=x, t=t, clip_denoised=clip_denoised)\n",
    "        noise = tf.random.normal(shape=x.shape, dtype=x.dtype)\n",
    "        # Нет шума, когда t == 0\n",
    "        nonzero_mask = tf.reshape(1 - tf.cast(tf.equal(t, 0), tf.float32), [tf.shape(x)[0], 1, 1, 1])\n",
    "        \n",
    "        return model_mean + nonzero_mask * tf.exp(0.5 * model_log_variance) * noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SR3DiffusionModel(keras.Model):\n",
    "    def __init__(self, network, ema_network, timesteps, gdf_util, ema=0.999):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.ema_network = ema_network\n",
    "        self.timesteps = timesteps\n",
    "        self.gdf_util = gdf_util\n",
    "\n",
    "    def plot_images(self, num_rows, num_cols, figsize, images):\n",
    "        images = (tf.clip_by_value(images * 127 + 127, 0.0, 255.0).numpy().astype(np.uint8))\n",
    "        _, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "        for i, image in enumerate(images):\n",
    "            if num_rows == 1:\n",
    "                if num_cols == 1:\n",
    "                    ax.imshow(image)\n",
    "                    ax.axis(\"off\")\n",
    "                else:\n",
    "                    ax[i].imshow(image)\n",
    "                    ax[i].axis(\"off\")\n",
    "            else:\n",
    "                ax[i // num_cols, i % num_cols].imshow(image)\n",
    "                ax[i // num_cols, i % num_cols].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def run_generation(self, small_images, num_rows=2, num_cols=8, figsize=(5, 2), annotation = \" \", ema_mode = True, ex_rate = 0, from_annotation = False):\n",
    "        num_images = num_rows * num_cols\n",
    "        small_images = small_images / 127 - 1\n",
    "        small_images = small_images / 2.0\n",
    "        self.plot_images(num_rows, num_cols, figsize, small_images*2.0)\n",
    "        \n",
    "        if from_annotation:\n",
    "            annotation = tf.expand_dims(annotation, axis = 0)\n",
    "            embedding = process_text(annotation)\n",
    "            embedding = tf.expand_dims(embedding, axis = 0)\n",
    "            embeddings = tf.repeat(embedding, num_images , axis = 0)\n",
    "            \n",
    "        if ex_rate > 0 or not from_annotation:\n",
    "             # 1.2 Преобразуем negative prompt в эмбеддинг\n",
    "            negative_prompt = \" \"\n",
    "            negative_prompt = tf.expand_dims(negative_prompt, axis = 0)\n",
    "            negative_embedding = process_text(negative_prompt)\n",
    "            negative_embedding = tf.expand_dims(negative_embedding, axis = 0)\n",
    "            negative_embeddings = tf.repeat(negative_embedding, num_images , axis = 0)\n",
    "            \n",
    "        if not from_annotation:\n",
    "            embeddings = negative_embeddings\n",
    "            \n",
    "        samples = tf.random.normal(shape=(num_images, 128, 128, 3), dtype=tf.float32) \n",
    "        bar = IntProgress(min=0, max=self.timesteps)\n",
    "        display(bar)\n",
    "        for t in reversed(range(0, self.timesteps)):\n",
    "            bar.value+=1\n",
    "            tt = tf.cast(tf.fill(num_images, t), dtype=tf.int64)\n",
    "            if ema_mode:\n",
    "                pred_noise = self.ema_network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "            else:\n",
    "                pred_noise = self.network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "            if ex_rate >0:\n",
    "                pred_negative_noise = self.ema_network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(negative_embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "                #Экстраполяция шума от negative в сторону positive\n",
    "                resulted_noise = pred_noise + (pred_noise - pred_negative_noise)*ex_rate\n",
    "            else:\n",
    "                resulted_noise = pred_noise     \n",
    "            samples = self.gdf_util.p_sample(resulted_noise, samples, tt, clip_denoised=True)\n",
    "        \n",
    "        generated_samples = samples\n",
    "        self.plot_images(num_rows, num_cols, figsize, generated_samples*2.0)\n",
    "        return (tf.clip_by_value((generated_samples*2.0) * 127 + 127, 0.0, 255.0).numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 300\n",
    "\n",
    "gdf_util = GaussianDiffusion(timesteps=total_timesteps)\n",
    "\n",
    "embedding_dims = 32\n",
    "embedding_max_frequency = 1000.0\n",
    "image_size = 128\n",
    "img_channels = 3\n",
    "\n",
    "network = tf.keras.models.load_model('sr3 32 to 128.h5')\n",
    "\n",
    "SR3model = SR3DiffusionModel(network=network, ema_network=network, gdf_util=gdf_util, timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR3_result = SR3model.run_generation(tf.expand_dims(small_image*256, axis = 0), num_rows=1, num_cols=1, ex_rate = 3, from_annotation = True, annotation = \"Some trees near the field\")[0]/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd801de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SR64DiffusionModel(keras.Model):\n",
    "    def __init__(self, network, ema_network, timesteps, gdf_util, ema=0.999):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.ema_network = ema_network\n",
    "        self.timesteps = timesteps\n",
    "        self.gdf_util = gdf_util\n",
    "\n",
    "    def plot_images(self, num_rows, num_cols, figsize, images):\n",
    "        images = (tf.clip_by_value(images * 127 + 127, 0.0, 255.0).numpy().astype(np.uint8))\n",
    "        _, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "        for i, image in enumerate(images):\n",
    "            if num_rows == 1:\n",
    "                if num_cols == 1:\n",
    "                    ax.imshow(image)\n",
    "                    ax.axis(\"off\")\n",
    "                else:\n",
    "                    ax[i].imshow(image)\n",
    "                    ax[i].axis(\"off\")\n",
    "            else:\n",
    "                ax[i // num_cols, i % num_cols].imshow(image)\n",
    "                ax[i // num_cols, i % num_cols].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def run_generation(self, small_images, num_rows=2, num_cols=8, figsize=(5, 2), annotation = \" \", ema_mode = True, ex_rate = 0, from_annotation = False):\n",
    "        num_images = num_rows * num_cols\n",
    "        small_images = small_images / 127 - 1\n",
    "        small_images = small_images / 2.0\n",
    "        small_images = tf.image.resize(small_images, (64,64), method = \"gaussian\")\n",
    "        self.plot_images(num_rows, num_cols, figsize, small_images*2.0)\n",
    "        \n",
    "        if from_annotation:\n",
    "            annotation = tf.expand_dims(annotation, axis = 0)\n",
    "            embedding = process_text(annotation)\n",
    "            embedding = tf.expand_dims(embedding, axis = 0)\n",
    "            embeddings = tf.repeat(embedding, num_images , axis = 0)\n",
    "            \n",
    "        if ex_rate > 0 or not from_annotation:\n",
    "             # 1.2 Преобразуем negative prompt в эмбеддинг\n",
    "            negative_prompt = \" \"\n",
    "            negative_prompt = tf.expand_dims(negative_prompt, axis = 0)\n",
    "            negative_embedding = process_text(negative_prompt)\n",
    "            negative_embedding = tf.expand_dims(negative_embedding, axis = 0)\n",
    "            negative_embeddings = tf.repeat(negative_embedding, num_images , axis = 0)\n",
    "            \n",
    "        if not from_annotation:\n",
    "            embeddings = negative_embeddings\n",
    "            \n",
    "        samples = tf.random.normal(shape=(num_images, 64, 64, 3), dtype=tf.float32) \n",
    "        bar = IntProgress(min=0, max=self.timesteps)\n",
    "        display(bar)\n",
    "        for t in reversed(range(0, self.timesteps)):\n",
    "            bar.value+=1\n",
    "            tt = tf.cast(tf.fill(num_images, t), dtype=tf.int64)\n",
    "            if ema_mode:\n",
    "                pred_noise = self.ema_network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "            else:\n",
    "                pred_noise = self.network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "            if ex_rate >0:\n",
    "                pred_negative_noise = self.ema_network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(negative_embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "                #Экстраполяция шума от negative в сторону positive\n",
    "                resulted_noise = pred_noise + (pred_noise - pred_negative_noise)*ex_rate\n",
    "            else:\n",
    "                resulted_noise = pred_noise     \n",
    "            samples = self.gdf_util.p_sample(resulted_noise, samples, tt, clip_denoised=True)\n",
    "        \n",
    "        generated_samples = samples\n",
    "        self.plot_images(num_rows, num_cols, figsize, generated_samples*2.0)\n",
    "        return (tf.clip_by_value((generated_samples*2.0) * 127 + 127, 0.0, 255.0).numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fce900",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 300\n",
    "\n",
    "# Get an instance of the Gaussian Diffusion utilities\n",
    "gdf_util = GaussianDiffusion(timesteps=total_timesteps)\n",
    "\n",
    "#устанавливаем то, что не сохраняется в h5 файл\n",
    "embedding_dims = 32\n",
    "embedding_max_frequency = 1000.0\n",
    "image_size = 128\n",
    "img_channels = 3\n",
    "\n",
    "network = tf.keras.models.load_model('sr3 32 to 64.h5')\n",
    "\n",
    "# Get the model\n",
    "SR64model = SR64DiffusionModel(network=network, ema_network=network, gdf_util=gdf_util, timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SR128DiffusionModel(keras.Model):\n",
    "    def __init__(self, network, ema_network, timesteps, gdf_util, ema=0.999):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.ema_network = ema_network\n",
    "        self.timesteps = timesteps\n",
    "        self.gdf_util = gdf_util\n",
    "\n",
    "    def plot_images(self, num_rows, num_cols, figsize, images):\n",
    "        images = (tf.clip_by_value(images * 127 + 127, 0.0, 255.0).numpy().astype(np.uint8))\n",
    "        _, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "        for i, image in enumerate(images):\n",
    "            if num_rows == 1:\n",
    "                if num_cols == 1:\n",
    "                    ax.imshow(image)\n",
    "                    ax.axis(\"off\")\n",
    "                else:\n",
    "                    ax[i].imshow(image)\n",
    "                    ax[i].axis(\"off\")\n",
    "            else:\n",
    "                ax[i // num_cols, i % num_cols].imshow(image)\n",
    "                ax[i // num_cols, i % num_cols].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def run_generation(self, small_images, num_rows=2, num_cols=8, figsize=(5, 2), annotation = \" \", ema_mode = True, ex_rate = 0, from_annotation = False):\n",
    "        num_images = num_rows * num_cols\n",
    "        small_images = small_images / 127 - 1\n",
    "        small_images = small_images / 2.0\n",
    "        small_images = tf.image.resize(small_images, (128,128), method = \"gaussian\")\n",
    "        self.plot_images(num_rows, num_cols, figsize, small_images*2.0)\n",
    "        \n",
    "        if from_annotation:\n",
    "            annotation = tf.expand_dims(annotation, axis = 0)\n",
    "            embedding = process_text(annotation)\n",
    "            embedding = tf.expand_dims(embedding, axis = 0)\n",
    "            embeddings = tf.repeat(embedding, num_images , axis = 0)\n",
    "            \n",
    "        if ex_rate > 0 or not from_annotation:\n",
    "             # 1.2 Преобразуем negative prompt в эмбеддинг\n",
    "            negative_prompt = \" \"\n",
    "            negative_prompt = tf.expand_dims(negative_prompt, axis = 0)\n",
    "            negative_embedding = process_text(negative_prompt)\n",
    "            negative_embedding = tf.expand_dims(negative_embedding, axis = 0)\n",
    "            negative_embeddings = tf.repeat(negative_embedding, num_images , axis = 0)\n",
    "            \n",
    "        if not from_annotation:\n",
    "            embeddings = negative_embeddings\n",
    "            \n",
    "        samples = tf.random.normal(shape=(num_images, 128, 128, 3), dtype=tf.float32) \n",
    "        bar = IntProgress(min=0, max=self.timesteps)\n",
    "        display(bar)\n",
    "        for t in reversed(range(0, self.timesteps)):\n",
    "            bar.value+=1\n",
    "            tt = tf.cast(tf.fill(num_images, t), dtype=tf.int64)\n",
    "            if ema_mode:\n",
    "                pred_noise = self.ema_network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "            else:\n",
    "                pred_noise = self.network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "            if ex_rate >0:\n",
    "                pred_negative_noise = self.ema_network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(negative_embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "                #Экстраполяция шума от negative в сторону positive\n",
    "                resulted_noise = pred_noise + (pred_noise - pred_negative_noise)*ex_rate\n",
    "            else:\n",
    "                resulted_noise = pred_noise     \n",
    "            samples = self.gdf_util.p_sample(resulted_noise, samples, tt, clip_denoised=True)\n",
    "        \n",
    "        generated_samples = samples\n",
    "        self.plot_images(num_rows, num_cols, figsize, generated_samples*2.0)\n",
    "        result = tf.clip_by_value((generated_samples*2.0) * 127 + 127, 0.0, 255.0)\n",
    "        return tf.clip_by_value(result, 0.0, 255.0).numpy().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 300\n",
    "\n",
    "gdf_util = GaussianDiffusion(timesteps=total_timesteps)\n",
    "\n",
    "embedding_dims = 32\n",
    "embedding_max_frequency = 1000.0\n",
    "image_size = 128\n",
    "img_channels = 3\n",
    "\n",
    "network = tf.keras.models.load_model('sr3 64 to 128.h5')\n",
    "\n",
    "SR128model = SR128DiffusionModel(network=network, ema_network=network, gdf_util=gdf_util, timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR64_result = SR64model.run_generation(tf.expand_dims(small_image*256, axis = 0), num_rows=1, num_cols=1, ex_rate = 3, from_annotation = True, annotation = \"A grass field\")[0]/256\n",
    "SR128_result = SR128model.run_generation(tf.expand_dims(SR64_result*256, axis = 0), num_rows=1, num_cols=1, ex_rate = 3, from_annotation = True, annotation = \"A grass field\")[0]/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c42d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2, 3, figsize=(20, 10))\n",
    "\n",
    "ax[0][0].imshow(tf.clip_by_value(original_image, 0, 1))\n",
    "ax[0][0].axis(\"off\")\n",
    "ax[0][0].set_title('Reference', fontsize=16)\n",
    "\n",
    "ax[0][1].imshow(tf.clip_by_value(bicubic_result, 0, 1))\n",
    "ax[0][1].axis(\"off\")\n",
    "ax[0][1].set_title('Bicubic', fontsize=16)\n",
    "\n",
    "ax[0][2].imshow(tf.clip_by_value(esrgan_result, 0, 1))\n",
    "ax[0][2].axis(\"off\")\n",
    "ax[0][2].set_title('Esrgan', fontsize=16)\n",
    "\n",
    "ax[1][0].imshow(tf.clip_by_value(regression_result, 0, 1))\n",
    "ax[1][0].axis(\"off\")\n",
    "ax[1][0].set_title('Regression', fontsize=16)\n",
    "\n",
    "ax[1][1].imshow(tf.clip_by_value(SR3_result, 0, 1))\n",
    "ax[1][1].axis(\"off\")\n",
    "ax[1][1].set_title('SR3', fontsize=16)\n",
    "\n",
    "ax[1][2].imshow(tf.clip_by_value(SR128_result, 0, 1))\n",
    "ax[1][2].axis(\"off\")\n",
    "ax[1][2].set_title('Cascade SR3', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR3_result_text = SR3model.run_generation(tf.expand_dims(small_image*256, axis = 0), num_rows=1, num_cols=1, ex_rate = 5, from_annotation = True, annotation = \"A dog on the green grass\")[0]/256\n",
    "SR3_result_no_text = SR3model.run_generation(tf.expand_dims(small_image*256, axis = 0), num_rows=1, num_cols=1, ex_rate = 0, from_annotation = False)[0]/256\n",
    "_, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "ax[0].imshow(tf.clip_by_value(SR3_result_no_text, 0, 1))\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title('No text', fontsize=16)\n",
    "\n",
    "ax[1].imshow(tf.clip_by_value(SR3_result_text, 0, 1))\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title('With text', fontsize=16)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486759ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record):\n",
    "    feature_description = {\n",
    "        'a': tf.io.FixedLenFeature([], tf.string),\n",
    "        'b': tf.io.FixedLenFeature([], tf.string),\n",
    "        'c': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    parsed_record = tf.io.parse_single_example(record, feature_description)\n",
    "    \n",
    "    a = tf.io.parse_tensor(parsed_record['a'], out_type=tf.string)\n",
    "    b = tf.io.parse_tensor(parsed_record['b'], out_type=tf.float32)\n",
    "    a = preprocess_image(a[0])\n",
    "    return a, b\n",
    "\n",
    "def preprocess_image(img_filename):\n",
    "    img_filename = tf.strings.regex_replace(img_filename, \" \", \"\")\n",
    "    img_filename = tf.strings.regex_replace(img_filename, \"\\\\\\\\\", \"/\")\n",
    "    img = tf.io.read_file('C:/users/user/desktop/' + img_filename)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "dataset = tf.data.TFRecordDataset('C:/users/user/ai tests/superresolution/halfmillion_custom_endless_no_images_shuffled.tfrecord')\n",
    "dataset = dataset.map(parse_record)\n",
    "dataset = dataset.shuffle(16000).prefetch(buffer_size=tf.data.AUTOTUNE).batch(32).shuffle(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7f58b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчитаем FID метрику\n",
    "#подробнее: https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/\n",
    "\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy import asarray\n",
    "from scipy.linalg import sqrtm\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "def calculate_fid(model, images1, images2):\n",
    "    act1 = model.predict(images1)\n",
    "    act2 = model.predict(images2)\n",
    "    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    if iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid\n",
    "\n",
    "inception_model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a22a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc = 0\n",
    "for images, annotations in dataset.take(1):\n",
    "    pass\n",
    "\n",
    "small_images = tf.image.resize(images, (32, 32), method = \"bicubic\")\n",
    "bicubic_result = tf.image.resize(small_images, (128, 128), method = \"bicubic\")\n",
    "\n",
    "esrgan_result = model_upscaler(small_images)\n",
    "\n",
    "regression_result = regression_sr(small_images/256)*256\n",
    "\n",
    "SR3_result = SR3model.run_generation(small_images, num_rows=4, num_cols=8, ex_rate = 0, figsize = (20, 10), from_annotation = False)\n",
    "\n",
    "SR64_result = SR64model.run_generation(small_images, num_rows=4, num_cols=8, ex_rate = 0, figsize = (20, 10), from_annotation = False)\n",
    "SR128_result = SR128model.run_generation(SR64_result, num_rows=4, num_cols=8, ex_rate = 0, figsize = (20, 10), from_annotation = False)\n",
    "\n",
    "\n",
    "images = preprocess_input(images)\n",
    "bicubic_result = preprocess_input(bicubic_result)\n",
    "esrgan_result = preprocess_input(esrgan_result)\n",
    "regression_result = preprocess_input(regression_result)\n",
    "SR3_result = preprocess_input(SR3_result)\n",
    "SR128_result = preprocess_input(SR128_result)\n",
    "\n",
    "images = tf.image.resize(images, (299,299))\n",
    "bicubic_result = tf.image.resize(bicubic_result, (299,299))\n",
    "esrgan_result = tf.image.resize(esrgan_result, (299,299))\n",
    "regression_result = tf.image.resize(regression_result, (299,299))\n",
    "SR3_result = tf.image.resize(SR3_result, (299,299))\n",
    "SR128_result = tf.image.resize(SR128_result, (299,299))\n",
    "\n",
    "print(\"Bicubic FID: \", calculate_fid(inception_model, images, bicubic_result))\n",
    "print(\"Esrgan FID: \", calculate_fid(inception_model, images, esrgan_result))\n",
    "print(\"Regression FID: \", calculate_fid(inception_model, images, regression_result))\n",
    "print(\"SR3 FID: \", calculate_fid(inception_model, images, SR3_result))\n",
    "print(\"Cascade SR3 FID: \", calculate_fid(inception_model, images, SR128_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9cbf5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
