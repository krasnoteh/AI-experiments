{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca4a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортируем все, что нужно\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D,AveragePooling2D,Conv2DTranspose, Input, Concatenate, Add, BatchNormalization, Activation, MultiHeadAttention\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from googletrans import Translator, constants\n",
    "import imageio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df9a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert\n",
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
    "\n",
    "def process_text(text_batch):\n",
    "    text_preprocessed = bert_preprocess_model(text_batch)\n",
    "    bert_results = bert_model(text_preprocessed)\n",
    "    return bert_results[\"pooled_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class GaussianDiffusion:\n",
    "    \"\"\"Утилита для гауссовского диффузии.\n",
    "\n",
    "    Args:\n",
    "        beta_start: Начальное значение дисперсии\n",
    "        beta_end: Конечное значение дисперсии\n",
    "        timesteps: Количество временных шагов в процессе прямой, а затем обратной диффузии\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, beta_start=1e-4, beta_end=0.02, timesteps=1000, clip_min=-1.0, clip_max=1.0):\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.timesteps = timesteps\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max\n",
    "\n",
    "        # Определение линейного расписания дисперсии\n",
    "        self.betas = betas = np.linspace(\n",
    "            beta_start,\n",
    "            beta_end,\n",
    "            timesteps,\n",
    "            dtype=np.float64,  # Тут используется float64 для лучшей точности\n",
    "        )\n",
    "        self.num_timesteps = int(timesteps)\n",
    "\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
    "\n",
    "        self.betas = tf.constant(betas, dtype=tf.float32)\n",
    "        self.alphas_cumprod = tf.constant(alphas_cumprod, dtype=tf.float32)\n",
    "        self.alphas_cumprod_prev = tf.constant(alphas_cumprod_prev, dtype=tf.float32)\n",
    "\n",
    "        # Расчеты для диффузии q(x_t | x_{t-1}) и других\n",
    "        self.sqrt_alphas_cumprod = tf.constant(np.sqrt(alphas_cumprod), dtype=tf.float32)\n",
    "\n",
    "        self.sqrt_one_minus_alphas_cumprod = tf.constant(np.sqrt(1.0 - alphas_cumprod), dtype=tf.float32)\n",
    "\n",
    "        self.log_one_minus_alphas_cumprod = tf.constant(np.log(1.0 - alphas_cumprod), dtype=tf.float32)\n",
    "\n",
    "        self.sqrt_recip_alphas_cumprod = tf.constant(np.sqrt(1.0 / alphas_cumprod), dtype=tf.float32)\n",
    "        self.sqrt_recipm1_alphas_cumprod = tf.constant(np.sqrt(1.0 / alphas_cumprod - 1), dtype=tf.float32)\n",
    "\n",
    "        # Расчеты для апостериорной q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = (betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod))\n",
    "        self.posterior_variance = tf.constant(posterior_variance, dtype=tf.float32)\n",
    "\n",
    "        # Обрезка расчета логарифма, так как апостериорная дисперсия равна 0 в начале цепочки диффузии\n",
    "        self.posterior_log_variance_clipped = tf.constant(np.log(np.maximum(posterior_variance, 1e-20)), dtype=tf.float32)\n",
    "\n",
    "        self.posterior_mean_coef1 = tf.constant(betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod),dtype=tf.float32,)\n",
    "\n",
    "        self.posterior_mean_coef2 = tf.constant(\n",
    "            (1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod),dtype=tf.float32)\n",
    "\n",
    "    def _extract(self, a, t, x_shape):\n",
    "        \"\"\"Извлекает некоторые коэффициенты в указанных временных шагах,\n",
    "        затем изменяет форму на [batch_size, 1, 1, 1, 1, ...] совпадения форм.\n",
    "\n",
    "        Args:\n",
    "            a: Тензор для извлечения\n",
    "            t: Временной шаг, для которого коэффициенты должны быть извлечены\n",
    "            x_shape: Форма текущих выборок в батче\n",
    "        \"\"\"\n",
    "        batch_size = x_shape[0]\n",
    "        out = tf.gather(a, t)\n",
    "        return tf.reshape(out, [batch_size, 1, 1, 1])\n",
    "\n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        \"\"\"Извлекает среднее значение и дисперсию на текущем временном шаге.\n",
    "\n",
    "        Args:\n",
    "            x_start: Начальный образец (перед первым шагом диффузии)\n",
    "            t: Текущий временной шаг\n",
    "        \"\"\"\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        mean = self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start\n",
    "        variance = self._extract(1.0 - self.alphas_cumprod, t, x_start_shape)\n",
    "        log_variance = self._extract(self.log_one_minus_alphas_cumprod, t, x_start_shape)\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def q_sample(self, x_start, t, noise):\n",
    "        \"\"\"Диффузия данных.\n",
    "\n",
    "        Args:\n",
    "            x_start: Начальный образец (перед первым шагом диффузии)\n",
    "            t: Текущий временной шаг\n",
    "            noise: Добавляемый гауссовский шум на текущем временном шаге\n",
    "        Returns:\n",
    "            Диффузионные образцы на временном шаге `t`\n",
    "        \"\"\"\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        \n",
    "        return (\n",
    "            self._extract(self.sqrt_alphas_cumprod, t, tf.shape(x_start)) * x_start\n",
    "            + self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start_shape)\n",
    "            * noise\n",
    "        )\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        \n",
    "        return (\n",
    "            self._extract(self.sqrt_recip_alphas_cumprod, t, x_t_shape) * x_t\n",
    "            - self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t_shape) * noise\n",
    "        )\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        \"\"\"Вычисляет среднее значение и дисперсию диффузии апостериорной q(x_{t-1} | x_t, x_0).\n",
    "\n",
    "        Args:\n",
    "            x_start: Точка начала (образец) для вычисления апостериори\n",
    "            x_t: Образец на временном шаге `t`\n",
    "            t: Текущий временной шаг\n",
    "        Returns:\n",
    "            Апостериорное среднее значение и дисперсия на текущем временном шаге\n",
    "        \"\"\"\n",
    "\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        posterior_mean = (\n",
    "            self._extract(self.posterior_mean_coef1, t, x_t_shape) * x_start\n",
    "            + self._extract(self.posterior_mean_coef2, t, x_t_shape) * x_t\n",
    "        )\n",
    "        posterior_variance = self._extract(self.posterior_variance, t, x_t_shape)\n",
    "        posterior_log_variance_clipped = self._extract(self.posterior_log_variance_clipped, t, x_t_shape)\n",
    "        \n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, pred_noise, x, t, clip_denoised=True):\n",
    "        x_recon = self.predict_start_from_noise(x, t=t, noise=pred_noise)\n",
    "        if clip_denoised:\n",
    "            x_recon = tf.clip_by_value(x_recon, self.clip_min, self.clip_max)\n",
    "\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n",
    "        \n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "\n",
    "    def p_sample(self, pred_noise, x, t, clip_denoised=True):\n",
    "        \"\"\"Выборка из модели диффузии.\n",
    "\n",
    "        Args:\n",
    "            pred_noise: Шум, предсказанный моделью диффузии\n",
    "            x: Образцы на определенном временном шаге, для которого был предсказан шум\n",
    "            t: Текущий временной шаг\n",
    "            clip_denoised (bool): Нужно ли обрезать предсказанный шум в указанном диапазоне или нет.\n",
    "        \"\"\"\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(pred_noise, x=x, t=t, clip_denoised=clip_denoised)\n",
    "        noise = tf.random.normal(shape=x.shape, dtype=x.dtype)\n",
    "        # Нет шума, когда t == 0\n",
    "        nonzero_mask = tf.reshape(1 - tf.cast(tf.equal(t, 0), tf.float32), [tf.shape(x)[0], 1, 1, 1])\n",
    "        \n",
    "        return model_mean + nonzero_mask * tf.exp(0.5 * model_log_variance) * noise\n",
    "\n",
    "    \n",
    "class DiffusionModel(keras.Model):\n",
    "    def __init__(self, network, ema_network, timesteps, gdf_util, ema=0.999):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.ema_network = ema_network\n",
    "        self.timesteps = timesteps\n",
    "        self.gdf_util = gdf_util\n",
    "        self.ema = ema\n",
    "\n",
    "\n",
    "    def generate_images(self, num_images=16, annotation = \" \", negative_prompt = \" \", ex_rate = 0):\n",
    "        \n",
    "        # 1.1 Преобразуем текст в эмбеддинг\n",
    "        annotation = tf.expand_dims(annotation, axis = 0)\n",
    "        embedding = process_text(annotation)\n",
    "        embedding = tf.expand_dims(embedding, axis = 0)\n",
    "        embeddings = tf.repeat(embedding, num_images , axis = 0)\n",
    "        \n",
    "        # 1.2 Преобразуем negative prompt в эмбеддинг\n",
    "        negative_prompt = tf.expand_dims(negative_prompt, axis = 0)\n",
    "        negative_embedding = process_text(negative_prompt)\n",
    "        negative_embedding = tf.expand_dims(negative_embedding, axis = 0)\n",
    "        negative_embeddings = tf.repeat(negative_embedding, num_images , axis = 0)\n",
    "        \n",
    "        # 2. Берем случайный шум\n",
    "        samples = tf.random.normal(shape=(num_images, 32, 32, 3), dtype=tf.float32)\n",
    "        \n",
    "        # 3. Применяем к нему нейросеть несколько раз\n",
    "        bar = IntProgress(min=0, max=self.timesteps) #прогресс-бар\n",
    "        display(bar)\n",
    "        for t in reversed(range(0, self.timesteps)):\n",
    "            bar.value+=1\n",
    "            tt = tf.cast(tf.fill(num_images, t), dtype=tf.int64)\n",
    "            pred_noise = self.ema_network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(embeddings, shape = (-1, 1,1,512))], verbose=0, batch_size=num_images)\n",
    "            if ex_rate >0:\n",
    "                pred_negative_noise = self.ema_network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(negative_embeddings, shape = (-1, 1,1,512))], verbose=0, batch_size=num_images)\n",
    "                #Экстраполяция шума от negative в сторону positive\n",
    "                resulted_noise = pred_noise + (pred_noise - pred_negative_noise)*ex_rate\n",
    "            else:\n",
    "                resulted_noise = pred_noise \n",
    "            samples = self.gdf_util.p_sample(resulted_noise, samples, tt, clip_denoised=True)\n",
    "            \n",
    "        #если нужен апскейлер\n",
    "        #samples = model_upscaler(samples * 127 + 127)\n",
    "        samples = tf.image.resize(samples*127+127, (32, 32), method = 'bilinear')\n",
    "        \n",
    "        return samples\n",
    "\n",
    "    def plot_images(self, epoch=None, logs=None, num_rows=2, num_cols=8, figsize=(12, 5), annotation = \" \", ex_rate = 0):\n",
    "        \n",
    "        generated_samples = self.generate_images(num_images=num_rows * num_cols, annotation = annotation, ex_rate = ex_rate)\n",
    "        generated_samples = (tf.clip_by_value(generated_samples, 0.0, 255.0).numpy().astype(np.uint8))\n",
    "        \n",
    "\n",
    "        _, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "        for i, image in enumerate(generated_samples):\n",
    "            if num_rows == 1:\n",
    "                ax[i].imshow(image)\n",
    "                ax[i].axis(\"off\")\n",
    "            else:\n",
    "                ax[i // num_cols, i % num_cols].imshow(image)\n",
    "                ax[i // num_cols, i % num_cols].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return generated_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c571002",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 300\n",
    "\n",
    "# Get an instance of the Gaussian Diffusion utilities\n",
    "gdf_util = GaussianDiffusion(timesteps=total_timesteps)\n",
    "\n",
    "#устанавливаем то, что не сохраняется в h5 файл\n",
    "embedding_dims = 32\n",
    "embedding_max_frequency = 1000.0\n",
    "image_size = 32\n",
    "img_channels = 3\n",
    "\n",
    "network = tf.keras.models.load_model('kt-diffusion-v4.h5')\n",
    "\n",
    "# Get the model\n",
    "model = DiffusionModel(network=network, ema_network=network, gdf_util=gdf_util, timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A forest near some water\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ad9f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#_ = model.plot_images(num_rows=4, num_cols=8, annotation = \"A Blue sky\")\n",
    "\n",
    "images = model.plot_images(num_rows=1, num_cols=8, annotation = prompt, ex_rate = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45176ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SR3DiffusionModel(keras.Model):\n",
    "    def __init__(self, network, ema_network, timesteps, gdf_util, ema=0.999):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.ema_network = ema_network\n",
    "        self.timesteps = timesteps\n",
    "        self.gdf_util = gdf_util\n",
    "\n",
    "    def plot_images(self, num_rows, num_cols, figsize, images):\n",
    "        images = (tf.clip_by_value(images * 127 + 127, 0.0, 255.0).numpy().astype(np.uint8))\n",
    "        _, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "        for i, image in enumerate(images):\n",
    "            if num_rows == 1:\n",
    "                if num_cols == 1:\n",
    "                    ax.imshow(image)\n",
    "                    ax.axis(\"off\")\n",
    "                else:\n",
    "                    ax[i].imshow(image)\n",
    "                    ax[i].axis(\"off\")\n",
    "            else:\n",
    "                ax[i // num_cols, i % num_cols].imshow(image)\n",
    "                ax[i // num_cols, i % num_cols].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def run_generation(self, small_images, num_rows=2, num_cols=8, figsize=(5, 2), annotation = \" \", ema_mode = True, ex_rate = 0, from_annotation = False):\n",
    "        num_images = num_rows * num_cols\n",
    "        small_images = small_images / 127 - 1\n",
    "        small_images = small_images / 2.0\n",
    "        self.plot_images(num_rows, num_cols, figsize, small_images*2.0)\n",
    "        \n",
    "        if from_annotation:\n",
    "            annotation = tf.expand_dims(annotation, axis = 0)\n",
    "            embedding = process_text(annotation)\n",
    "            embedding = tf.expand_dims(embedding, axis = 0)\n",
    "            embeddings = tf.repeat(embedding, num_images , axis = 0)\n",
    "            \n",
    "        if ex_rate > 0 or not from_annotation:\n",
    "             # 1.2 Преобразуем negative prompt в эмбеддинг\n",
    "            negative_prompt = \" \"\n",
    "            negative_prompt = tf.expand_dims(negative_prompt, axis = 0)\n",
    "            negative_embedding = process_text(negative_prompt)\n",
    "            negative_embedding = tf.expand_dims(negative_embedding, axis = 0)\n",
    "            negative_embeddings = tf.repeat(negative_embedding, num_images , axis = 0)\n",
    "            \n",
    "        if not from_annotation:\n",
    "            embeddings = negative_embeddings\n",
    "            \n",
    "        samples = tf.random.normal(shape=(num_images, 128, 128, 3), dtype=tf.float32) \n",
    "        bar = IntProgress(min=0, max=self.timesteps)\n",
    "        display(bar)\n",
    "        for t in reversed(range(0, self.timesteps)):\n",
    "            bar.value+=1\n",
    "            tt = tf.cast(tf.fill(num_images, t), dtype=tf.int64)\n",
    "            if ema_mode:\n",
    "                pred_noise = self.ema_network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "            else:\n",
    "                pred_noise = self.network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "            if ex_rate >0:\n",
    "                pred_negative_noise = self.ema_network.predict([samples, tf.reshape(tt, shape = (-1, 1,1,1)), tf.reshape(negative_embeddings, shape = (-1, 1,1,512)), small_images], verbose=0, batch_size=num_images)\n",
    "                #Экстраполяция шума от negative в сторону positive\n",
    "                resulted_noise = pred_noise + (pred_noise - pred_negative_noise)*ex_rate\n",
    "            else:\n",
    "                resulted_noise = pred_noise     \n",
    "            samples = self.gdf_util.p_sample(resulted_noise, samples, tt, clip_denoised=True)\n",
    "        \n",
    "        generated_samples = samples\n",
    "        self.plot_images(num_rows, num_cols, figsize, generated_samples*2.0)\n",
    "        \n",
    "        return tf.clip_by_value((generated_samples*2.0+1)*127, 0.0, 255.0).numpy().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18604bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 300\n",
    "\n",
    "gdf_util = GaussianDiffusion(timesteps=total_timesteps)\n",
    "\n",
    "embedding_dims = 32\n",
    "embedding_max_frequency = 1000.0\n",
    "image_size = 128\n",
    "img_channels = 3\n",
    "\n",
    "network = tf.keras.models.load_model('kt-sr.h5')\n",
    "\n",
    "SR3model = SR3DiffusionModel(network=network, ema_network=network, gdf_util=gdf_util, timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f7d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#картинку нужно сохранить, чтобы отправить через бота\n",
    "def save_image(image, filename):\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = tf.clip_by_value(image, 0, 255)\n",
    "        image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "        image.save(\"%s.jpg\" % filename)\n",
    "        print(\"Saved as %s.jpg\" % filename)\n",
    "\n",
    "#в разработке\n",
    "def crop_square_from_center(image, crop_percentage):\n",
    "    if crop_percentage <= 0 or crop_percentage > 100:\n",
    "        raise ValueError(\"Invalid crop_percentage. It should be between 0 and 100.\")\n",
    "    crop_size = int(image.shape[0] * (crop_percentage / 100))\n",
    "    offset_y = (tf.shape(image)[0] - crop_size) // 2\n",
    "    offset_x = (tf.shape(image)[1] - crop_size) // 2\n",
    "    cropped_image = tf.image.crop_to_bounding_box(image, offset_y, offset_x, crop_size, crop_size)\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "#в разработке\n",
    "def image_to_video_crop(image):\n",
    "    buffer = []\n",
    "    for i in range(16):\n",
    "        im = crop_square_from_center(image, 90 + math.sin((i/16)*math.pi*2)*10)\n",
    "        im = tf.image.resize(im, (32, 32), method = 'nearest')\n",
    "        im = tf.expand_dims(im, axis = 0)\n",
    "        buffer.append(im)\n",
    "    result = tf.concat(buffer, axis = 0)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "from PIL import Image    \n",
    "import telebot\n",
    "import threading\n",
    "import time\n",
    "from telebot import types\n",
    "\n",
    "queue = []\n",
    "database = {}\n",
    "exit_flag = False\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "#ключ к боту\n",
    "bot = telebot.TeleBot('6032...-- token --...4c')\n",
    "\n",
    "@bot.message_handler(commands=['start'])\n",
    "def start(message):\n",
    "\n",
    "    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "    bot.send_message(message.from_user.id, \"Здравствуй! Напиши запрос сюда\", reply_markup=markup)\n",
    "\n",
    "@bot.message_handler(content_types=['text'])\n",
    "def get_text_messages(message):\n",
    "    print(message.text)\n",
    "    try:\n",
    "        text = message.text\n",
    "        video_mode = False\n",
    "        if text[0] == \"v\":\n",
    "            text = text[1:]\n",
    "            video_mode = True\n",
    "        n = int(text)\n",
    "        if database[message.from_user.id] != None:\n",
    "            if n < 0 or n > 16:\n",
    "                bot.send_message(message.from_user.id, \"Номер должен быть от 1 до 16\", parse_mode='Markdown')\n",
    "            else:\n",
    "                count = 0\n",
    "                for q in queue:\n",
    "                    if q[0] == message.from_user.id:\n",
    "                        count+=1\n",
    "                if count < 3:\n",
    "                    queue.append([message.from_user.id, database[message.from_user.id], n, video_mode])\n",
    "                    bot.send_message(message.from_user.id, 'Место в очереди: ' + str(len(queue))+ '. Подождите около '+ str(len(queue) * 2) + ' мин.', parse_mode='Markdown')\n",
    "                else:\n",
    "                    bot.send_message(message.from_user.id, \"Подождите, пока выполнятся предыдущие запросы\", parse_mode='Markdown')\n",
    "    except Exception:\n",
    "        count = 0\n",
    "        for q in queue:\n",
    "            if q[0] == message.from_user.id:\n",
    "                count+=1\n",
    "        if count < 3:\n",
    "            queue.append([message.from_user.id, translator.translate(message.text).text])\n",
    "            bot.send_message(message.from_user.id, 'Место в очереди: ' + str(len(queue))+ '. Подождите около '+ str(len(queue) * 2) + ' мин.', parse_mode='Markdown')\n",
    "        else:\n",
    "            bot.send_message(message.from_user.id, \"Подождите, пока выполнятся предыдущие запросы\", parse_mode='Markdown')\n",
    "        \n",
    "def background_task():\n",
    "    global exit_flag\n",
    "    while not exit_flag:\n",
    "        if len(queue) > 0:\n",
    "            data = queue[0]\n",
    "            if len(data) == 2:\n",
    "                images = model.plot_images(num_rows=1, num_cols=16, annotation = data[1], ex_rate = 2)\n",
    "                database[data[0]] = [images, data[1]]\n",
    "                image = np.zeros((1024, 1024, 3), dtype = np.float32)\n",
    "                for x in range(4):\n",
    "                    for y in range(4):\n",
    "                        index = x*4 + y\n",
    "                        image[x*256:x*256+256, y*256:y*256+256, :] = tf.image.resize(images[index], (256, 256))\n",
    "\n",
    "\n",
    "                save_image(image, filename=\"Image\")\n",
    "                img = open('Image.jpg', 'rb')\n",
    "                bot.send_photo(data[0], img, caption = 'Результат по запросу: '+ data[1])\n",
    "                bot.send_message(data[0], \"Чтобы доделать одну из картинок введите ее номер. Чтобы сделать ролик, добавьте 'v' перед номером. Либо введите следующий запрос\", parse_mode='Markdown')\n",
    "            if len(data) == 4:\n",
    "                if not data[3]:\n",
    "                    image = SR3model.run_generation(tf.expand_dims(data[1][0][data[2] - 1], axis = 0), figsize = (5,2), num_rows=1, num_cols=1, annotation = data[1][1], from_annotation = True, ex_rate = 4)\n",
    "                    save_image(tf.image.resize(image[0], (1024, 1024), method = 'nearest'), filename=\"Image\")\n",
    "                    img = open('Image.jpg', 'rb')\n",
    "                    bot.send_photo(data[0], img, caption = 'Результат по запросу: '+ data[1][1])\n",
    "                else:\n",
    "                    batch = tf.repeat(tf.expand_dims(data[1][0][data[2] - 1], axis = 0), 16, axis = 0)\n",
    "                    #batch = image_to_video_crop(data[1][0][data[2] - 1]) #в разработке\n",
    "                    image = SR3model.run_generation(batch, figsize = (20, 10), num_rows=2, num_cols=8, annotation = data[1][1], from_annotation = True, ex_rate = 4)\n",
    "                    images_array = image\n",
    "                    output_path = 'animated.gif'\n",
    "                    frames = []\n",
    "                    for i in range(images_array.shape[0]):\n",
    "                        current_frame = images_array[i, :, :, :]\n",
    "                        frames.append(current_frame.astype(np.uint8))\n",
    "                    imageio.mimsave(output_path, frames, fps=10)\n",
    "                    img = open('animated.gif', 'rb')\n",
    "                    bot.send_animation(data[0], img, caption = 'Результат по запросу: '+ data[1][1])\n",
    "            queue.pop(0)\n",
    "            \n",
    "background_thread = threading.Thread(target=background_task)\n",
    "\n",
    "try:\n",
    "    background_thread.start()\n",
    "    bot.polling()\n",
    "\n",
    "finally:\n",
    "    exit_flag = True\n",
    "    background_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05da71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
